import cv2
import numpy as np
import serial
import time
import sys
import os
from serial.tools import list_ports


# ---------- —É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è PyInstaller (–∏—â–µ–º —Ñ–∞–π–ª—ã –≤–Ω—É—Ç—Ä–∏ .exe) ----------
def resource_path(relative_path):
    """
    –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∫–∞–∫ .py –±–µ—Ä—ë—Ç —Ñ–∞–π–ª—ã –∏–∑ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–∏,
    –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∫–∞–∫ .exe (PyInstaller) ‚Äî –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–π.
    """
    if hasattr(sys, "_MEIPASS"):
        base_path = sys._MEIPASS
    else:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)


# ---------- –ø–æ–∏—Å–∫ –ø–æ—Ä—Ç–∞ Arduino ----------
def find_arduino_port():
    ports = list_ports.comports()
    for p in ports:
        desc = p.description.lower()
        if "arduino" in desc or "ch340" in desc or "usb-serial" in desc:
            return p.device
    return None


# ---------- —Å–≤—è–∑—å —Å Arduino ----------
def connect_arduino(baudrate=9600):
    port = find_arduino_port()
    if port is None:
        print("‚ùå Arduino –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–¥–∫–ª—é—á–∏ –ø–ª–∞—Ç—É –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º–º—É.")
        return None
    try:
        ser = serial.Serial(port, baudrate, timeout=1)
        time.sleep(2)
        print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Arduino –Ω–∞ –ø–æ—Ä—Ç—É {port}")
        return ser
    except Exception as e:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –ø–æ—Ä—Ç Arduino:", e)
        return None


def send(ser, cmd):
    if ser is None:
        return
    try:
        ser.write((cmd + "\n").encode("utf-8"))
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Arduino:", e)


def open_camera():
    """
    –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—á—É—é –∫–∞–º–µ—Ä—É —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ 0..4.
    –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–º–µ—Ä:
      - –µ—Å–ª–∏ –æ–¥–Ω–∞ ‚Äì –±–µ—Ä—ë–º –µ—ë
      - –µ—Å–ª–∏ 2+ ‚Äì –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä—ë–º –≤—Ç–æ—Ä—É—é (–∏–Ω–¥–µ–∫—Å 1), —Ç.–∫. –Ω–∞ –Ω–æ—É—Ç–µ —ç—Ç–æ —á–∞—â–µ –≤—Å–µ–≥–æ USB.
    –ù–∞ Windows –∏—Å–ø–æ–ª—å–∑—É–µ–º DirectShow (CAP_DSHOW).
    """
    is_windows = os.name == "nt"
    working_cams = []

    print("üîç –ò—â–µ–º –∫–∞–º–µ—Ä—ã...")

    for idx in range(5):
        if is_windows:
            cap = cv2.VideoCapture(idx, cv2.CAP_DSHOW)
        else:
            cap = cv2.VideoCapture(idx)

        if cap.isOpened():
            # –ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –æ–¥–∏–Ω –∫–∞–¥—Ä, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è
            ret, _ = cap.read()
            if ret:
                print(f"‚úÖ –ö–∞–º–µ—Ä–∞ —Å –∏–Ω–¥–µ–∫—Å–æ–º {idx} —Ä–∞–±–æ—Ç–∞–µ—Ç")
                working_cams.append(idx)
            cap.release()
        else:
            cap.release()

    if not working_cams:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –Ω–∏ –æ–¥–Ω—É –∫–∞–º–µ—Ä—É (–∏–Ω–¥–µ–∫—Å—ã 0..4). "
              "–ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –¥—Ä—É–≥–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–±–∫–∞–º–µ—Ä—É.")
        return None

    # –µ—Å–ª–∏ –æ–¥–Ω–∞ –∫–∞–º–µ—Ä–∞ ‚Äî –±–µ—Ä—ë–º –µ—ë
    if len(working_cams) == 1:
        cam_index = working_cams[0]
        print(f"‚ñ∂ –ù–∞–π–¥–µ–Ω–∞ –æ–¥–Ω–∞ –∫–∞–º–µ—Ä–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å {cam_index}")
    else:
        # –µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ ‚Äî –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä—ë–º –≤—Ç–æ—Ä—É—é (–æ–±—ã—á–Ω–æ USB, –∏–Ω–¥–µ–∫—Å 1)
        if 1 in working_cams:
            cam_index = 1
            print(f"‚ñ∂ –ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–º–µ—Ä, –≤—ã–±–∏—Ä–∞–µ–º –∏–Ω–¥–µ–∫—Å 1 (—á–∞—Å—Ç–æ USB)")
        else:
            cam_index = working_cams[0]
            print(f"‚ñ∂ –ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –≤ —Å–ø–∏—Å–∫–µ: –∏–Ω–¥–µ–∫—Å {cam_index}")

    # –æ—Ç–∫—Ä—ã–≤–∞–µ–º —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—É—é –∫–∞–º–µ—Ä—É
    if is_windows:
        cap = cv2.VideoCapture(cam_index, cv2.CAP_DSHOW)
    else:
        cap = cv2.VideoCapture(cam_index)

    if not cap.isOpened():
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É —Å –∏–Ω–¥–µ–∫—Å–æ–º {cam_index}")
        return None

    print(f"üé• –†–∞–±–æ—Ç–∞–µ–º —Å –∫–∞–º–µ—Ä–æ–π –∏–Ω–¥–µ–∫—Å {cam_index}")
    return cap

# ---------- –∑–∞–≥—Ä—É–∑–∫–∞ YOLO ----------
cfg_path = resource_path(os.path.join("models", "yolov3-tiny.cfg"))
weights_path = resource_path(os.path.join("models", "yolov3-tiny.weights"))
names_path = resource_path(os.path.join("models", "coco.names"))

net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)

with open(names_path, "r") as f:
    classes = [line.strip() for line in f.readlines()]

TARGET_CLASSES = ["car", "truck", "bus"]
ln = net.getUnconnectedOutLayersNames()

# ---------- —Å—Ç–∞—Ä—Ç ----------
ser = connect_arduino()

current_light = "R"
send(ser, "R")

# —Ä–µ–∂–∏–º –ø–µ—Ä–µ—Ö–æ–¥–∞ G -> Y -> R
transition_state = None      # None –∏–ª–∏ "Y_WAIT"
transition_start = 0.0       # –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –º–∏–≥–∞–Ω–∏—è –∂—ë–ª—Ç—ã–º

# –æ—Ç–∫—Ä—ã–≤–∞–µ–º –∫–∞–º–µ—Ä—É
cap = open_camera()
if cap is None:
    sys.exit(1)

print("‚ñ∂ –ó–∞–ø—É—Å–∫ TrafficAI. –ù–∞–∂–º–∏ 'q' –≤ –æ–∫–Ω–µ –≤–∏–¥–µ–æ –¥–ª—è –≤—ã—Ö–æ–¥–∞.")

while True:
    ret, frame = cap.read()
    if not ret:
        print("–ù–µ—Ç –∫–∞–¥—Ä–∞ —Å –∫–∞–º–µ—Ä—ã")
        break

    (H, W) = frame.shape[:2]

    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416),
                                 swapRB=True, crop=False)
    net.setInput(blob)
    layer_outputs = net.forward(ln)

    cars_count = 0
    boxes = []
    confidences = []
    class_ids = []

    for output in layer_outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            conf = scores[class_id]
            if conf > 0.4 and classes[class_id] in TARGET_CLASSES:
                box = detection[0:4] * np.array([W, H, W, H])
                (cX, cY, w, h) = box.astype("int")
                x = int(cX - w/2)
                y = int(cY - h/2)
                boxes.append([x, y, int(w), int(h)])
                confidences.append(float(conf))
                class_ids.append(class_id)

    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.3)

    if len(idxs) > 0:
        for i in idxs.flatten():
            x, y, w, h = boxes[i]
            cars_count += 1
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # --- –ª–æ–≥–∏–∫–∞ —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞ —Å –ø–æ—Ä–æ–≥–æ–º –∏ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ ---

    # 1) –µ—Å–ª–∏ —Å–µ–π—á–∞—Å –∏–¥—ë—Ç –ø–µ—Ä–µ—Ö–æ–¥ (–º–∏–≥–∞–Ω–∏–µ –∂—ë–ª—Ç—ã–º), –ø—Ä–æ—Å—Ç–æ –∂–¥—ë–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    if transition_state == "Y_WAIT":
        # –∂–¥—ë–º 2.0 —Å–µ–∫, –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã
        if time.time() - transition_start >= 2.0:
            # –Ω–∞ Arduino —Ä–µ–∂–∏–º 'Y' —É–∂–µ —Å–∞–º –≤–∫–ª—é—á–∏–ª –∫—Ä–∞—Å–Ω—ã–π,
            # –º—ã —Ç–æ–ª—å–∫–æ –æ–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            current_light = "R"
            transition_state = None
        # –≤ —Ä–µ–∂–∏–º–µ Y_WAIT –º—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥ –∏ –Ω–µ –º–µ–Ω—è–µ–º desired
    else:
        # 2) –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: —Å—á–∏—Ç–∞–µ–º, –∫–∞–∫–æ–π —Ü–≤–µ—Ç –Ω—É–∂–µ–Ω
        # –∑–µ–ª—ë–Ω—ã–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–∞—à–∏–Ω > 3
        if cars_count > 3:
            desired = "G"
        else:
            desired = "R"

        # –ø–µ—Ä–µ—Ö–æ–¥ G -> R: —Å–Ω–∞—á–∞–ª–∞ –∂—ë–ª—Ç—ã–π –º–∏–≥–∞—é—â–∏–π
        if current_light == "G" and desired == "R":
            print("–ú–∞—à–∏–Ω –º–µ–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ 3 ‚Üí –º–∏–≥–∞–µ–º –∂—ë–ª—Ç—ã–º –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –∫—Ä–∞—Å–Ω—ã–π")
            send(ser, "Y")                 # Arduino –º–∏–≥–∞–µ—Ç –∂—ë–ª—Ç—ã–º –∏ —Å–∞–º –≤–∫–ª—é—á–∞–µ—Ç –∫—Ä–∞—Å–Ω—ã–π
            transition_state = "Y_WAIT"
            transition_start = time.time()  # –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞
        elif desired != current_light and transition_state is None:
            # –æ–±—ã—á–Ω–∞—è —Å–º–µ–Ω–∞ (–Ω–∞–ø—Ä. R -> G)
            print(f"–ú–µ–Ω—è–µ–º —Å–≤–µ—Ç: {current_light} ‚Üí {desired}")
            send(ser, desired)
            current_light = desired

    cv2.putText(frame, f"Cars: {cars_count}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

    cv2.imshow("TrafficAI", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
if ser is not None:
    ser.close()
cv2.destroyAllWindows()
